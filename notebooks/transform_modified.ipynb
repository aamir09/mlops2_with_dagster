{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:10:22.473534: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-30 13:10:22.505871: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-30 13:10:22.506667: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-30 13:10:22,977 - DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2023-08-30 13:10:23.029334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-30 13:10:23,154 - DEBUG - Creating converter from 7 to 5\n",
      "2023-08-30 13:10:23,155 - DEBUG - Creating converter from 5 to 7\n",
      "2023-08-30 13:10:23,155 - DEBUG - Creating converter from 7 to 5\n",
      "2023-08-30 13:10:23,156 - DEBUG - Creating converter from 5 to 7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jupyter-aamir09/mlops2_with_dagster/\")\n",
    "\n",
    "\n",
    "from mlops2_with_dagster import encoder_pipeline, features_pipeline\n",
    "from pathlib import Path\n",
    "from joblib import dump, load\n",
    "from hamilton import driver, base\n",
    "from mlops2_with_dagster.utils import get_project_dir, printse\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    LabelEncoder\n",
    ")\n",
    "from ortho.utils.logger import Logger\n",
    "from ortho.ortho.decorators.task import task\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd \n",
    "import mlflow as mf\n",
    "from ortho.ortho.callbacks.mlflow import MlFlowCallBack\n",
    "from ortho.ortho.callbacks.logger import LoggerCallBack\n",
    "import os\n",
    "\n",
    "\n",
    "logger = Logger().logger()\n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> project_dir: /home/jupyter-aamir09/mlops2_with_dagster\n"
     ]
    }
   ],
   "source": [
    "project = 'mlops2_with_dagster'\n",
    "project_dir = get_project_dir(project)\n",
    "printse(f'project_dir: {project_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data : Path = project_dir/\"data/train.csv\"\n",
    "test_data : Path = project_dir/\"data/test.csv\"\n",
    "encoder_file: Path = project_dir/\"warehouse/encoders.joblib\"\n",
    "data: Path = project_dir/\"data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:10:23,722 - INFO - Context impl SQLiteImpl.\n",
      "2023-08-30 13:10:23,723 - INFO - Will assume non-transactional DDL.\n",
      "2023-08-30 13:10:23,735 - INFO - Running stamp_revision  -> 5771160a95ad\n",
      "2023-08-30 13:10:23,735 - DEBUG - new branch insert 5771160a95ad\n",
      "2023-08-30 13:10:23,749 - INFO - Context impl SQLiteImpl.\n",
      "2023-08-30 13:10:23,750 - INFO - Will assume non-transactional DDL.\n",
      "2023-08-30 13:10:23,760 - INFO - Running stamp_revision  -> 5771160a95ad\n",
      "2023-08-30 13:10:23,760 - DEBUG - new branch insert 5771160a95ad\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "import dagstermill\n",
    "df = pd.read_csv(data)\n",
    "encoders = load(encoder_file)\n",
    "context = dagstermill.get_context(op_config={'datatype': 'xxxx'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transforms:\n",
    "    \n",
    "    def __init__(self, callbacks,  experiment_name, run_name, load_from_artifact=False):\n",
    "        self.load_from_artifact = load_from_artifact\n",
    "        self.callbacks = callbacks\n",
    "        self.experiment_name = experiment_name\n",
    "        self.run_name = run_name\n",
    "        os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = self.experiment_name\n",
    "        os.environ[\"MLFLOW_RUN_NAME\"] = self.run_name\n",
    "        \n",
    "        self.index_col = 'passengerid'\n",
    "        self.target_col = \"survived\"\n",
    "        self.cat_cols = [\"sex\", \"cabin\", \"embarked\"]\n",
    "        self.config = {\n",
    "            'index_column': self.index_col,\n",
    "            'target_column': self.target_col,\n",
    "            'categorical_columns': self.cat_cols\n",
    "        }\n",
    "    \n",
    "    @task(build_on_previous_run=True, end_mlflow_run=False)       \n",
    "    def transform(self, df_train, encoders=None):\n",
    "        transform_dr = driver.Driver(self.config, encoder_pipeline, features_pipeline)\n",
    "        ddf = dict(df = df_train, **encoders['encoders'])\n",
    "        output_nodes = ['final_imputed_features']\n",
    "        \n",
    "        output = transform_dr.execute(output_nodes, inputs = ddf)\n",
    "        \n",
    "        data = {\"transformed_data\": output }\n",
    "        payload = {\"artifact_path\": \"/home/jupyter-aamir09/mlops2_with_dagster/artifacts/mlflow_artfacts\"}\n",
    "        \n",
    "        return data, payload\n",
    "    \n",
    "    def run(self, *args, **kwargs):\n",
    "        \n",
    "        return self.transform(*args, **kwargs)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:13:48,162 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,168 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=Mlflow_with_Dagster HTTP/1.1\" 200 241\n",
      "2023-08-30 13:13:48,170 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,177 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=1f0a6e058efb4c5d9e9fbecc36928d78&run_id=1f0a6e058efb4c5d9e9fbecc36928d78 HTTP/1.1\" 200 1260\n",
      "2023-08-30 13:13:48,179 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,184 - DEBUG - http://127.0.0.1:5002 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 423\n",
      "2023-08-30 13:13:48,186 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,191 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=1f0a6e058efb4c5d9e9fbecc36928d78&run_id=1f0a6e058efb4c5d9e9fbecc36928d78 HTTP/1.1\" 200 1260\n",
      "2023-08-30 13:13:48,192 - INFO - Successfuly initiated run with name BadamBhum and id 1f0a6e058efb4c5d9e9fbecc36928d78\n",
      "2023-08-30 13:13:48,192 - INFO - Active run_id recieved as 1f0a6e058efb4c5d9e9fbecc36928d78\n",
      "2023-08-30 13:13:48,192 - INFO - Active run_id recieved as 1f0a6e058efb4c5d9e9fbecc36928d78\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:46: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  print(client.download_artifacts(mlflow_run_id, fname))\n",
      "2023-08-30 13:13:48,194 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,196 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Fdf_train.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:13:48,198 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,200 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 13:13:48,200 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle'): Retry(total=4, connect=5, read=5, redirect=5, status=4)\n",
      "2023-08-30 13:13:48,201 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle\n",
      "2023-08-30 13:13:48,201 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,203 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 13:13:48,203 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle'): Retry(total=3, connect=5, read=5, redirect=5, status=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self', 'df_train', 'encoders']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:13:52,208 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle\n",
      "2023-08-30 13:13:52,210 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:52,215 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 13:13:52,216 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle'): Retry(total=2, connect=5, read=5, redirect=5, status=2)\n",
      "2023-08-30 13:14:00,226 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle\n",
      "2023-08-30 13:14:00,228 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:00,233 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 13:14:00,234 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle'): Retry(total=1, connect=5, read=5, redirect=5, status=1)\n",
      "2023-08-30 13:14:16,251 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle\n",
      "2023-08-30 13:14:16,253 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:16,258 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 13:14:16,259 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle'): Retry(total=0, connect=5, read=5, redirect=5, status=0)\n",
      "2023-08-30 13:14:48,293 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle\n",
      "2023-08-30 13:14:48,295 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,299 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 13:14:48,300 - INFO - The following error occured while loading files from artefact store, The following failures occurred while downloading one or more artifacts from http://127.0.0.1:5002/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts: {'df_train.pickle': 'MlflowException(\"API request to http://127.0.0.1:5002/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle failed with exception HTTPConnectionPool(host=\\'127.0.0.1\\', port=5002): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle (Caused by ResponseError(\\'too many 500 error responses\\'))\")'}\n",
      "2023-08-30 13:14:48,306 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,308 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Fencoders.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:14:48,310 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,312 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/encoders.pickle HTTP/1.1\" 200 None\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:47: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  inputs.append(pickle.load(open(client.download_artifacts(mlflow_run_id, fname), \"rb\")))\n",
      "2023-08-30 13:14:48,315 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,317 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Fencoders.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:14:48,319 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,321 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/encoders.pickle HTTP/1.1\" 200 None\n",
      "2023-08-30 13:14:48,322 - INFO - Succesfully loaded file with name encoders.pickle\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:49: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  response[fname.replace(\".pickle\", \"\")] = pickle.load(open(client.download_artifacts(mlflow_run_id, fname), \"rb\"))\n",
      "2023-08-30 13:14:48,326 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,328 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Fencoders.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:14:48,330 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,332 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/encoders.pickle HTTP/1.1\" 200 None\n",
      "2023-08-30 13:14:48,338 - DEBUG - Computing df.\n",
      "2023-08-30 13:14:48,339 - DEBUG - Computing index_column.\n",
      "2023-08-30 13:14:48,339 - DEBUG - Computing input_data.\n",
      "2023-08-30 13:14:48,349 - DEBUG - Computing target_column.\n",
      "2023-08-30 13:14:48,349 - DEBUG - Computing features.\n",
      "2023-08-30 13:14:48,357 - DEBUG - Computing pclass.\n",
      "2023-08-30 13:14:48,358 - DEBUG - Computing age.\n",
      "2023-08-30 13:14:48,358 - DEBUG - Computing fare.\n",
      "2023-08-30 13:14:48,359 - DEBUG - Computing cabin.\n",
      "2023-08-30 13:14:48,359 - DEBUG - Computing cabin_t.\n",
      "2023-08-30 13:14:48,374 - DEBUG - Computing cabinencoder.\n",
      "2023-08-30 13:14:48,375 - DEBUG - Computing cabin_category.\n",
      "2023-08-30 13:14:48,432 - DEBUG - Computing sex.\n",
      "2023-08-30 13:14:48,433 - DEBUG - Computing sexencoder.\n",
      "2023-08-30 13:14:48,433 - DEBUG - Computing sex_category.\n",
      "2023-08-30 13:14:48,444 - DEBUG - Computing embarked.\n",
      "2023-08-30 13:14:48,444 - DEBUG - Computing embarkedencoder.\n",
      "2023-08-30 13:14:48,444 - DEBUG - Computing embarked_category.\n",
      "2023-08-30 13:14:48,453 - DEBUG - Computing sibsp.\n",
      "2023-08-30 13:14:48,454 - DEBUG - Computing parch.\n",
      "2023-08-30 13:14:48,454 - DEBUG - Computing family.\n",
      "2023-08-30 13:14:48,455 - DEBUG - Computing engineered_features.\n",
      "2023-08-30 13:14:48,461 - DEBUG - Computing final_imputed_features.\n",
      "2023-08-30 13:14:48,467 - DEBUG - Index types encountered:\n",
      "{'Index:::int64': ['final_imputed_features']}.\n",
      "2023-08-30 13:14:48,472 - INFO - Successfuly stored transformed_data to /home/jupyter-aamir09/mlops2_with_dagster/artifacts/mlflow_artfacts/transformed_data.pickle\n",
      "2023-08-30 13:14:48,475 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,485 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/target.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:14:48,487 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,511 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/transformed_data.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:14:48,513 - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmptyislrj1/encoders.pickle\n",
      "{'encoders': {'encoders': {'cabinencoder': LabelEncoder(), 'sexencoder': LabelEncoder(), 'embarkedencoder': LabelEncoder()}}}\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:14:48,515 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/encoders.pickle HTTP/1.1\" 200 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin_category</th>\n",
       "      <th>sex_category</th>\n",
       "      <th>embarked_category</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passengerid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.35</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "      <td>71.29</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19.00</td>\n",
       "      <td>13.04</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>25.00</td>\n",
       "      <td>7.76</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>2</td>\n",
       "      <td>62.00</td>\n",
       "      <td>14.86</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>2</td>\n",
       "      <td>66.00</td>\n",
       "      <td>11.15</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>3</td>\n",
       "      <td>37.00</td>\n",
       "      <td>9.95</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>3</td>\n",
       "      <td>51.00</td>\n",
       "      <td>30.92</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>3</td>\n",
       "      <td>55.00</td>\n",
       "      <td>13.96</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pclass    age   fare  cabin_category  sex_category  \\\n",
       "passengerid                                                       \n",
       "0                 1   0.00  27.14               2             1   \n",
       "1                 3   0.00  13.35               8             1   \n",
       "2                 3   0.33  71.29               8             1   \n",
       "3                 3  19.00  13.04               8             1   \n",
       "4                 3  25.00   7.76               8             1   \n",
       "...             ...    ...    ...             ...           ...   \n",
       "99995             2  62.00  14.86               3             0   \n",
       "99996             2  66.00  11.15               8             1   \n",
       "99997             3  37.00   9.95               8             1   \n",
       "99998             3  51.00  30.92               8             1   \n",
       "99999             3  55.00  13.96               8             1   \n",
       "\n",
       "             embarked_category  family  \n",
       "passengerid                             \n",
       "0                            2       2  \n",
       "1                            2       0  \n",
       "2                            2       3  \n",
       "3                            2       0  \n",
       "4                            2       0  \n",
       "...                        ...     ...  \n",
       "99995                        0       0  \n",
       "99996                        2       0  \n",
       "99997                        2       0  \n",
       "99998                        2       1  \n",
       "99999                        2       0  \n",
       "\n",
       "[100000 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:14:48,630 - DEBUG - Succeed in sending telemetry consisting of [b'{\"api_key\": \"phc_mZg8bkn3yvMxqvZKRlMlxjekFU5DFDdcdAsijJ2EH5e\", \"event\": \"os_hamilton_run_start\", \"properties\": {\"os_type\": \"posix\", \"os_version\": \"Linux-5.4.0-124-generic-x86_64-with-glibc2.31\", \"python_version\": \"3.10.12/CPython\", \"distinct_id\": \"e4e272c1-5845-4b12-8bd8-09d84d585dbc\", \"hamilton_version\": [1, 27, 2], \"telemetry_version\": \"0.0.1\", \"number_of_nodes\": 42, \"number_of_modules\": 2, \"number_of_config_items\": 3, \"decorators_used\": {\"parameterize_sources\": 4, \"extract_columns\": 2, \"extract_fields\": 1}, \"graph_adapter_used\": \"hamilton.base.SimplePythonDataFrameGraphAdapter\", \"result_builder_used\": \"hamilton.base.PandasDataFrameResult\", \"driver_run_id\": \"88beb813-e398-4538-b488-766ef32a2c10\", \"error\": null, \"graph_executor_class\": \"DefaultGraphExecutor\"}}'].\n",
      "2023-08-30 13:14:48,710 - DEBUG - Succeed in sending telemetry consisting of [b'{\"api_key\": \"phc_mZg8bkn3yvMxqvZKRlMlxjekFU5DFDdcdAsijJ2EH5e\", \"event\": \"os_hamilton_run_end\", \"properties\": {\"os_type\": \"posix\", \"os_version\": \"Linux-5.4.0-124-generic-x86_64-with-glibc2.31\", \"python_version\": \"3.10.12/CPython\", \"distinct_id\": \"e4e272c1-5845-4b12-8bd8-09d84d585dbc\", \"hamilton_version\": [1, 27, 2], \"telemetry_version\": \"0.0.1\", \"is_success\": true, \"runtime_seconds\": 0.1288890838623047, \"number_of_outputs\": 1, \"number_of_overrides\": 0, \"number_of_inputs\": 0, \"driver_run_id\": \"88beb813-e398-4538-b488-766ef32a2c10\", \"error\": null}}'].\n"
     ]
    }
   ],
   "source": [
    "import dagstermill\n",
    "transformer = Transforms(experiment_name=\"Mlflow_with_Dagster\",\n",
    "                          run_name=\"BadamBhum\",\n",
    "                          callbacks = [LoggerCallBack(\"/home/jupyter-aamir09/mlops2_with_dagster/notebooks\", kernel_names=[\"transform\"]),\n",
    "                                       MlFlowCallBack(kernel_names=[\"transform\"])])\n",
    "\n",
    "# mf.end_run()\n",
    "dagstermill.yield_result(transformer.run(df_train=df, encoders=encoders)[0][\"transformed_data\"], output_name=\"transformed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_with_poetry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
