{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:15:24.602208: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-30 13:15:24.634739: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-30 13:15:24.635542: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-30 13:15:25,111 - DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2023-08-30 13:15:25.163636: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-30 13:15:25,290 - DEBUG - Creating converter from 7 to 5\n",
      "2023-08-30 13:15:25,291 - DEBUG - Creating converter from 5 to 7\n",
      "2023-08-30 13:15:25,292 - DEBUG - Creating converter from 7 to 5\n",
      "2023-08-30 13:15:25,292 - DEBUG - Creating converter from 5 to 7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jupyter-aamir09/mlops2_with_dagster/\")\n",
    "\n",
    "\n",
    "\n",
    "from mlops2_with_dagster import model_pipeline, features_pipeline\n",
    "from pathlib import Path\n",
    "from joblib import dump, load\n",
    "from hamilton import driver, base\n",
    "from mlops2_with_dagster.utils import get_project_dir, printse\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    LabelEncoder\n",
    ")\n",
    "from ortho.utils.logger import Logger\n",
    "from ortho.ortho.decorators.task import task\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd \n",
    "import mlflow as mf\n",
    "from ortho.ortho.callbacks.mlflow import MlFlowCallBack\n",
    "from ortho.ortho.callbacks.logger import LoggerCallBack\n",
    "import os\n",
    "\n",
    "\n",
    "logger = Logger().logger()\n",
    "\n",
    "   \n",
    "ARTIFACT_PATH = \"/home/jupyter-aamir09/mlops2_with_dagster/artifacts/mlflow_artfacts\"\n",
    "LOGGER_FOLDER_PATH = \"/home/jupyter-aamir09/mlops2_with_dagster/notebooks\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> project_dir: /home/jupyter-aamir09/mlops2_with_dagster\n"
     ]
    }
   ],
   "source": [
    "project = 'mlops2_with_dagster'\n",
    "project_dir = get_project_dir(project)\n",
    "printse(f'project_dir: {project_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data : Path = project_dir/\"data/train.csv\"\n",
    "test_data : Path = project_dir/\"data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_file: str = f\"{project_dir}/warehouse/featurestore_train.parquet\"\n",
    "target_file: str = f\"{project_dir}/warehouse/target.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "train_features = pd.read_parquet(train_features_file)\n",
    "target = pd.read_parquet(target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    \n",
    "    def __init__(self, callbacks,  experiment_name, run_name, load_from_artifact=False):\n",
    "        self.load_from_artifact = load_from_artifact\n",
    "        self.callbacks = callbacks\n",
    "        self.experiment_name = experiment_name\n",
    "        self.run_name = run_name\n",
    "        os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = self.experiment_name\n",
    "        os.environ[\"MLFLOW_RUN_NAME\"] = self.run_name\n",
    "        \n",
    "        self.index_col = 'passengerid'\n",
    "        self.target_col = \"survived\"\n",
    "        self.cat_cols = [\"sex\", \"cabin\", \"embarked\"]\n",
    "        self.config = {\n",
    "            'index_column': self.index_col,\n",
    "            'target_column': self.target_col,\n",
    "            'categorical_columns': self.cat_cols\n",
    "        }\n",
    "        \n",
    "        self.config_model = {\n",
    "            'index_column': self.index_col,\n",
    "            'target_column': self.target_col,\n",
    "            'random_state': 42,\n",
    "            'max_depth': None,\n",
    "            'validation_size_fraction': 0.33,\n",
    "            't': 0.5\n",
    "        }\n",
    "    \n",
    "    @task(build_on_previous_run=True, end_mlflow_run=False)       \n",
    "    def fit(self, transformed_data=None, target=None):\n",
    "        training_adapter = base.SimplePythonGraphAdapter(base.DictResult())\n",
    "        training_dr = driver.Driver(self.config_model, \n",
    "                           model_pipeline,\n",
    "                           adapter=training_adapter)\n",
    "        dtraining = dict(\n",
    "            final_feature_matrix = transformed_data,\n",
    "            target = target.target\n",
    "        )\n",
    "        output_nodes = ['fit_clf', 'train_predictions', 'valid_predictions']\n",
    "        \n",
    "        output = training_dr.execute(output_nodes, inputs = dtraining)\n",
    "        \n",
    "        data = {\"training_outputs\": output }\n",
    "        payload = {\"artifact_path\": ARTIFACT_PATH,\n",
    "                \"params\":self.config_model}\n",
    "        return data, payload\n",
    "        \n",
    "    def run(self, *args, **kwargs):\n",
    "        return self.fit(*args, **kwargs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:15:25,701 - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5002\n",
      "2023-08-30 13:15:25,706 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=Mlflow_with_Dagster HTTP/1.1\" 200 241\n",
      "2023-08-30 13:15:25,708 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:25,712 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=1f0a6e058efb4c5d9e9fbecc36928d78&run_id=1f0a6e058efb4c5d9e9fbecc36928d78 HTTP/1.1\" 200 1260\n",
      "2023-08-30 13:15:25,714 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:25,718 - DEBUG - http://127.0.0.1:5002 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 423\n",
      "2023-08-30 13:15:25,720 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:25,724 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=1f0a6e058efb4c5d9e9fbecc36928d78&run_id=1f0a6e058efb4c5d9e9fbecc36928d78 HTTP/1.1\" 200 1260\n",
      "2023-08-30 13:15:25,724 - INFO - Successfuly initiated run with name BadamBhum and id 1f0a6e058efb4c5d9e9fbecc36928d78\n",
      "2023-08-30 13:15:25,725 - INFO - Active run_id recieved as 1f0a6e058efb4c5d9e9fbecc36928d78\n",
      "2023-08-30 13:15:25,725 - INFO - Active run_id recieved as 1f0a6e058efb4c5d9e9fbecc36928d78\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:46: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  print(client.download_artifacts(mlflow_run_id, fname))\n",
      "2023-08-30 13:15:25,727 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:25,731 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=1f0a6e058efb4c5d9e9fbecc36928d78&run_id=1f0a6e058efb4c5d9e9fbecc36928d78 HTTP/1.1\" 200 1260\n",
      "2023-08-30 13:15:25,733 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:25,734 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Ftransformed_data.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:15:25,739 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:25,748 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/transformed_data.pickle HTTP/1.1\" 200 None\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:47: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  inputs.append(pickle.load(open(client.download_artifacts(mlflow_run_id, fname), \"rb\")))\n",
      "2023-08-30 13:15:25,858 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:25,860 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Ftransformed_data.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:15:25,862 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:25,869 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/transformed_data.pickle HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self', 'transformed_data', 'target']\n",
      "/tmp/tmp2aoartol/transformed_data.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:15:25,981 - INFO - Succesfully loaded file with name transformed_data.pickle\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:49: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  response[fname.replace(\".pickle\", \"\")] = pickle.load(open(client.download_artifacts(mlflow_run_id, fname), \"rb\"))\n",
      "2023-08-30 13:15:25,984 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:25,986 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Ftransformed_data.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:15:25,989 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:25,998 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/transformed_data.pickle HTTP/1.1\" 200 None\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:46: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  print(client.download_artifacts(mlflow_run_id, fname))\n",
      "2023-08-30 13:15:26,115 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:26,117 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Ftarget.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:15:26,120 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:26,124 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/target.pickle HTTP/1.1\" 200 None\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:47: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  inputs.append(pickle.load(open(client.download_artifacts(mlflow_run_id, fname), \"rb\")))\n",
      "2023-08-30 13:15:26,131 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:26,132 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Ftarget.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:15:26,134 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:26,137 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/target.pickle HTTP/1.1\" 200 None\n",
      "2023-08-30 13:15:26,143 - INFO - Succesfully loaded file with name target.pickle\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:49: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  response[fname.replace(\".pickle\", \"\")] = pickle.load(open(client.download_artifacts(mlflow_run_id, fname), \"rb\"))\n",
      "2023-08-30 13:15:26,145 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:26,146 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Ftarget.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:15:26,148 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:26,151 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/target.pickle HTTP/1.1\" 200 None\n",
      "2023-08-30 13:15:26,163 - WARNING - Note: Hamilton collects completely anonymous data about usage. This will help us improve Hamilton over time. See https://github.com/dagworks-inc/hamilton#usage-analytics--data-privacy for details.\n",
      "2023-08-30 13:15:26,164 - DEBUG - Computing random_state.\n",
      "2023-08-30 13:15:26,165 - DEBUG - Computing max_depth.\n",
      "2023-08-30 13:15:26,165 - DEBUG - Computing prefit_clf.\n",
      "2023-08-30 13:15:26,165 - DEBUG - Computing final_feature_matrix.\n",
      "2023-08-30 13:15:26,166 - DEBUG - Computing target.\n",
      "2023-08-30 13:15:26,166 - DEBUG - Computing validation_size_fraction.\n",
      "2023-08-30 13:15:26,167 - DEBUG - Computing train_valid_split_func.\n",
      "2023-08-30 13:15:26,194 - DEBUG - Computing X_train.\n",
      "2023-08-30 13:15:26,195 - DEBUG - Computing y_train.\n",
      "2023-08-30 13:15:26,195 - DEBUG - Computing fit_clf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpme_mwud4/target.pickle\n",
      "{'transformed_data':              pclass    age   fare  cabin_category  sex_category  \\\n",
      "passengerid                                                       \n",
      "0                 1   0.00  27.14               2             1   \n",
      "1                 3   0.00  13.35               8             1   \n",
      "2                 3   0.33  71.29               8             1   \n",
      "3                 3  19.00  13.04               8             1   \n",
      "4                 3  25.00   7.76               8             1   \n",
      "...             ...    ...    ...             ...           ...   \n",
      "99995             2  62.00  14.86               3             0   \n",
      "99996             2  66.00  11.15               8             1   \n",
      "99997             3  37.00   9.95               8             1   \n",
      "99998             3  51.00  30.92               8             1   \n",
      "99999             3  55.00  13.96               8             1   \n",
      "\n",
      "             embarked_category  family  \n",
      "passengerid                             \n",
      "0                            2       2  \n",
      "1                            2       0  \n",
      "2                            2       3  \n",
      "3                            2       0  \n",
      "4                            2       0  \n",
      "...                        ...     ...  \n",
      "99995                        0       0  \n",
      "99996                        2       0  \n",
      "99997                        2       0  \n",
      "99998                        2       1  \n",
      "99999                        2       0  \n",
      "\n",
      "[100000 rows x 7 columns], 'target':              target\n",
      "passengerid        \n",
      "0                 1\n",
      "1                 0\n",
      "2                 0\n",
      "3                 0\n",
      "4                 1\n",
      "...             ...\n",
      "99995             1\n",
      "99996             0\n",
      "99997             0\n",
      "99998             0\n",
      "99999             0\n",
      "\n",
      "[100000 rows x 1 columns]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:15:26,438 - DEBUG - Succeed in sending telemetry consisting of [b'{\"api_key\": \"phc_mZg8bkn3yvMxqvZKRlMlxjekFU5DFDdcdAsijJ2EH5e\", \"event\": \"os_hamilton_run_start\", \"properties\": {\"os_type\": \"posix\", \"os_version\": \"Linux-5.4.0-124-generic-x86_64-with-glibc2.31\", \"python_version\": \"3.10.12/CPython\", \"distinct_id\": \"e4e272c1-5845-4b12-8bd8-09d84d585dbc\", \"hamilton_version\": [1, 27, 2], \"telemetry_version\": \"0.0.1\", \"number_of_nodes\": 22, \"number_of_modules\": 1, \"number_of_config_items\": 6, \"decorators_used\": {\"parameterize_sources\": 4, \"extract_columns\": 2, \"extract_fields\": 1}, \"graph_adapter_used\": \"hamilton.base.SimplePythonGraphAdapter\", \"result_builder_used\": \"hamilton.base.DictResult\", \"driver_run_id\": \"1f5e43de-c8c5-4ae0-b944-8387d81c3b2f\", \"error\": null, \"graph_executor_class\": \"DefaultGraphExecutor\"}}'].\n",
      "2023-08-30 13:15:31,154 - DEBUG - Computing t.\n",
      "2023-08-30 13:15:31,155 - DEBUG - Computing train_predictions.\n",
      "2023-08-30 13:15:32,405 - DEBUG - Computing X_valid.\n",
      "2023-08-30 13:15:32,406 - DEBUG - Computing valid_predictions.\n",
      "2023-08-30 13:15:33,058 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:33,078 - DEBUG - http://127.0.0.1:5002 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2023-08-30 13:15:33,284 - INFO - Successfuly stored training_outputs to /home/jupyter-aamir09/mlops2_with_dagster/artifacts/mlflow_artfacts/training_outputs.pickle\n",
      "2023-08-30 13:15:33,288 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:33,297 - DEBUG - Succeed in sending telemetry consisting of [b'{\"api_key\": \"phc_mZg8bkn3yvMxqvZKRlMlxjekFU5DFDdcdAsijJ2EH5e\", \"event\": \"os_hamilton_run_end\", \"properties\": {\"os_type\": \"posix\", \"os_version\": \"Linux-5.4.0-124-generic-x86_64-with-glibc2.31\", \"python_version\": \"3.10.12/CPython\", \"distinct_id\": \"e4e272c1-5845-4b12-8bd8-09d84d585dbc\", \"hamilton_version\": [1, 27, 2], \"telemetry_version\": \"0.0.1\", \"is_success\": true, \"runtime_seconds\": 6.890893459320068, \"number_of_outputs\": 3, \"number_of_overrides\": 0, \"number_of_inputs\": 0, \"driver_run_id\": \"1f5e43de-c8c5-4ae0-b944-8387d81c3b2f\", \"error\": null}}'].\n",
      "2023-08-30 13:15:33,301 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/target.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:15:33,303 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:33,326 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/transformed_data.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:15:33,329 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:34,034 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/training_outputs.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:15:34,038 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:15:34,040 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/encoders.pickle HTTP/1.1\" 200 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_clf': RandomForestClassifier(random_state=42),\n",
       " 'train_predictions': (array([0.2   , 0.76  , 0.17  , ..., 0.6775, 0.84  , 0.83  ]),\n",
       "  array([0, 1, 0, ..., 1, 1, 1])),\n",
       " 'valid_predictions': (array([0.62, 0.01, 0.01, ..., 0.38, 0.28, 0.64]),\n",
       "  array([1, 0, 0, ..., 0, 0, 1]))}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagstermill\n",
    "import pickle\n",
    "trainer = Train(experiment_name=\"Mlflow_with_Dagster\",\n",
    "                          run_name=\"BadamBhum\",\n",
    "                          callbacks = [LoggerCallBack(LOGGER_FOLDER_PATH, kernel_names=[\"fit\"]),\n",
    "                                       MlFlowCallBack(kernel_names=[\"fit\"])],\n",
    "                         )\n",
    "\n",
    "# mf.end_run() #Document why it his here \n",
    "output = trainer.run(transformed_data=train_features, target=target)[0][\"training_outputs\"]\n",
    "dagstermill.yield_result(output, output_name=\"training_outputs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_with_poetry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
