{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 00:31:24.278210: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-15 00:31:24.376784: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-15 00:31:24.378965: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-15 00:31:27,441 - DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2023-09-15 00:31:27.740307: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-15 00:31:27,839 - DEBUG - Creating converter from 7 to 5\n",
      "2023-09-15 00:31:27,841 - DEBUG - Creating converter from 5 to 7\n",
      "2023-09-15 00:31:27,844 - DEBUG - Creating converter from 7 to 5\n",
      "2023-09-15 00:31:27,848 - DEBUG - Creating converter from 5 to 7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Tuple\n",
    "import pandas as pd \n",
    "import mlflow as mf\n",
    "\n",
    "## replace with your specific paths\n",
    "sys.path.append(\"/home/aamir07/mlops2_with_dagster/\") \n",
    "ARTIFACT_PATH = \"/home/aamir07/mlops2_with_dagster/artifacts/mlflow_artfacts\" \n",
    "LOGGER_FOLDER_PATH = \"/home/aamir07/mlops2_with_dagster/notebooks\"\n",
    "\n",
    "from mlops2_with_dagster import model_pipeline, features_pipeline\n",
    "from pathlib import Path\n",
    "from joblib import dump, load\n",
    "from hamilton import driver, base\n",
    "from mlops2_with_dagster.utils import get_project_dir, printse\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    LabelEncoder\n",
    ")\n",
    "\n",
    "from ortho import BaseKernel\n",
    "from ortho.utils import Logger\n",
    "from ortho.ortho.decorators import task\n",
    "from ortho.ortho.callbacks import MlFlowCallBack, LoggerCallBack\n",
    "\n",
    "\n",
    "logger = Logger().logger()\n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> project_dir: /home/aamir07/mlops2_with_dagster\n"
     ]
    }
   ],
   "source": [
    "project = 'mlops2_with_dagster'\n",
    "project_dir = get_project_dir(project)\n",
    "printse(f'project_dir: {project_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data : Path = project_dir/\"data/train.csv\"\n",
    "test_data : Path = project_dir/\"data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_file: str = f\"{project_dir}/warehouse/transformed_data.parquet\"\n",
    "target_file: str = f\"{project_dir}/warehouse/target.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "train_features = pd.read_parquet(train_features_file)\n",
    "target = pd.read_parquet(target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train(BaseKernel):\n",
    "    \n",
    "    def __init__(self, callbacks,  experiment_name, run_name, load_from_artifact=False):\n",
    "        super().__init__(callbacks,\n",
    "                       experiment_name,\n",
    "                       run_name,\n",
    "                       load_from_artifact)\n",
    "        \n",
    "        self.index_col = 'passengerid'\n",
    "        self.target_col = \"survived\"\n",
    "        self.cat_cols = [\"sex\", \"cabin\", \"embarked\"]\n",
    "        self.config = {\n",
    "            'index_column': self.index_col,\n",
    "            'target_column': self.target_col,\n",
    "            'categorical_columns': self.cat_cols\n",
    "        }\n",
    "        \n",
    "        self.config_model = {\n",
    "            'index_column': self.index_col,\n",
    "            'target_column': self.target_col,\n",
    "            'random_state': 42,\n",
    "            'max_depth': None,\n",
    "            'validation_size_fraction': 0.33,\n",
    "            't': 0.5\n",
    "        }\n",
    "    \n",
    "    @task(build_on_previous_run=True, end_mlflow_run=False)       \n",
    "    def fit(self, transformed_data=None, target=None):\n",
    "        training_adapter = base.SimplePythonGraphAdapter(base.DictResult())\n",
    "        training_dr = driver.Driver(self.config_model, \n",
    "                           model_pipeline,\n",
    "                           adapter=training_adapter)\n",
    "        dtraining = dict(\n",
    "            final_feature_matrix = transformed_data,\n",
    "            target = target.target\n",
    "        )\n",
    "        output_nodes = ['fit_clf', 'train_predictions', 'valid_predictions']\n",
    "        \n",
    "        output = training_dr.execute(output_nodes, inputs = dtraining)\n",
    "        \n",
    "        data = {\"training_outputs\": output }\n",
    "        payload = {\"artifact_path\": ARTIFACT_PATH,\n",
    "                \"params\":self.config_model}\n",
    "        return data, payload\n",
    "        \n",
    "    def run(self, *args, **kwargs):\n",
    "        return self.fit(*args, **kwargs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 00:31:30,872 - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5002\n",
      "2023-09-15 00:31:31,339 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=Mlflow_with_Dagster HTTP/1.1\" 200 241\n",
      "2023-09-15 00:31:31,349 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-09-15 00:31:31,390 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=a05f805113ff42a3b54371547a26d49b&run_id=a05f805113ff42a3b54371547a26d49b HTTP/1.1\" 200 1572\n",
      "2023-09-15 00:31:31,399 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-09-15 00:31:31,500 - DEBUG - http://127.0.0.1:5002 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 423\n",
      "2023-09-15 00:31:31,508 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-09-15 00:31:31,561 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=a05f805113ff42a3b54371547a26d49b&run_id=a05f805113ff42a3b54371547a26d49b HTTP/1.1\" 200 1571\n",
      "2023-09-15 00:31:31,566 - INFO - Successfuly initiated run with name BadamBhum and id a05f805113ff42a3b54371547a26d49b\n",
      "2023-09-15 00:31:31,575 - WARNING - Note: Hamilton collects completely anonymous data about usage. This will help us improve Hamilton over time. See https://github.com/dagworks-inc/hamilton#usage-analytics--data-privacy for details.\n",
      "2023-09-15 00:31:31,587 - DEBUG - Computing random_state.\n",
      "2023-09-15 00:31:31,590 - DEBUG - Computing max_depth.\n",
      "2023-09-15 00:31:31,594 - DEBUG - Computing prefit_clf.\n",
      "2023-09-15 00:31:31,599 - DEBUG - Computing final_feature_matrix.\n",
      "2023-09-15 00:31:31,603 - DEBUG - Computing target.\n",
      "2023-09-15 00:31:31,606 - DEBUG - Computing validation_size_fraction.\n",
      "2023-09-15 00:31:31,609 - DEBUG - Computing train_valid_split_func.\n",
      "2023-09-15 00:31:31,727 - DEBUG - Computing X_train.\n",
      "2023-09-15 00:31:31,729 - DEBUG - Computing y_train.\n",
      "2023-09-15 00:31:31,732 - DEBUG - Computing fit_clf.\n",
      "2023-09-15 00:31:32,124 - DEBUG - Succeed in sending telemetry consisting of [b'{\"api_key\": \"phc_mZg8bkn3yvMxqvZKRlMlxjekFU5DFDdcdAsijJ2EH5e\", \"event\": \"os_hamilton_run_start\", \"properties\": {\"os_type\": \"posix\", \"os_version\": \"Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-glibc2.35\", \"python_version\": \"3.10.11/CPython\", \"distinct_id\": \"f41b7308-274c-4333-ab85-eca6fe911802\", \"hamilton_version\": [1, 28, 0], \"telemetry_version\": \"0.0.1\", \"number_of_nodes\": 22, \"number_of_modules\": 1, \"number_of_config_items\": 6, \"decorators_used\": {\"parameterize_sources\": 4, \"extract_columns\": 2, \"extract_fields\": 1}, \"graph_adapter_used\": \"hamilton.base.SimplePythonGraphAdapter\", \"result_builder_used\": \"hamilton.base.DictResult\", \"driver_run_id\": \"f3cee8d2-8547-4262-a4f9-284ffc951978\", \"error\": null, \"graph_executor_class\": \"DefaultGraphExecutor\"}}'].\n",
      "2023-09-15 00:32:01,357 - DEBUG - Computing t.\n",
      "2023-09-15 00:32:01,359 - DEBUG - Computing train_predictions.\n",
      "2023-09-15 00:32:05,359 - DEBUG - Computing X_valid.\n",
      "2023-09-15 00:32:05,361 - DEBUG - Computing valid_predictions.\n",
      "2023-09-15 00:32:07,646 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-09-15 00:32:07,775 - DEBUG - http://127.0.0.1:5002 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2023-09-15 00:32:08,172 - DEBUG - Succeed in sending telemetry consisting of [b'{\"api_key\": \"phc_mZg8bkn3yvMxqvZKRlMlxjekFU5DFDdcdAsijJ2EH5e\", \"event\": \"os_hamilton_run_end\", \"properties\": {\"os_type\": \"posix\", \"os_version\": \"Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-glibc2.35\", \"python_version\": \"3.10.11/CPython\", \"distinct_id\": \"f41b7308-274c-4333-ab85-eca6fe911802\", \"hamilton_version\": [1, 28, 0], \"telemetry_version\": \"0.0.1\", \"is_success\": true, \"runtime_seconds\": 36.05225205421448, \"number_of_outputs\": 3, \"number_of_overrides\": 0, \"number_of_inputs\": 0, \"driver_run_id\": \"f3cee8d2-8547-4262-a4f9-284ffc951978\", \"error\": null}}'].\n",
      "2023-09-15 00:32:08,815 - INFO - Successfuly stored training_outputs to /home/aamir07/mlops2_with_dagster/artifacts/mlflow_artfacts/training_outputs.pickle\n",
      "2023-09-15 00:32:08,988 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-09-15 00:32:09,045 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=a05f805113ff42a3b54371547a26d49b&run_id=a05f805113ff42a3b54371547a26d49b HTTP/1.1\" 200 1571\n",
      "2023-09-15 00:32:09,536 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-09-15 00:32:09,667 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/a05f805113ff42a3b54371547a26d49b/artifacts/transformed_data.pickle HTTP/1.1\" 200 2\n",
      "2023-09-15 00:32:09,677 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-09-15 00:32:09,691 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/a05f805113ff42a3b54371547a26d49b/artifacts/encoders.pickle HTTP/1.1\" 200 2\n",
      "2023-09-15 00:32:09,704 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-09-15 00:32:13,557 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/a05f805113ff42a3b54371547a26d49b/artifacts/training_outputs.pickle HTTP/1.1\" 200 2\n",
      "2023-09-15 00:32:13,566 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-09-15 00:32:13,878 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/a05f805113ff42a3b54371547a26d49b/artifacts/target.pickle HTTP/1.1\" 200 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_clf': RandomForestClassifier(random_state=42),\n",
       " 'train_predictions': (array([0.66   , 0.07   , 0.14   , ..., 0.1    , 0.50875, 0.22   ]),\n",
       "  array([1, 0, 0, ..., 0, 1, 0])),\n",
       " 'valid_predictions': (array([0.47      , 0.19      , 0.87      , ..., 0.31533333, 0.32      ,\n",
       "         0.42      ]),\n",
       "  array([0, 0, 1, ..., 0, 0, 0]))}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagstermill\n",
    "import pickle\n",
    "trainer = Train(experiment_name=\"Mlflow_with_Dagster\",\n",
    "                          run_name=\"BadamBhum\",\n",
    "                          callbacks = [LoggerCallBack(log_folder=LOGGER_FOLDER_PATH,\n",
    "                                                      kernel_names=[\"fit\"]),\n",
    "                                       MlFlowCallBack(kernel_names=[\"fit\"])],\n",
    "                         )\n",
    "\n",
    "# mf.end_run() #Document why it his here \n",
    "output = trainer.run(transformed_data=train_features, target=target)[0][\"training_outputs\"]\n",
    "dagstermill.yield_result(output, output_name=\"training_outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_with_poetry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
