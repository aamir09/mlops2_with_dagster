{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jupyter-aamir09/mlops2_with_dagster/\")\n",
    "\n",
    "\n",
    "from mlops2_with_dagster import encoder_pipeline, features_pipeline, model_pipeline\n",
    "from pathlib import Path\n",
    "from joblib import dump, load\n",
    "from hamilton import driver, base\n",
    "from mlops2_with_dagster.utils import get_project_dir, printse\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    LabelEncoder\n",
    ")\n",
    "from ortho.utils.logger import Logger\n",
    "from ortho.ortho.decorators.task import task\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd \n",
    "import mlflow as mf\n",
    "from ortho.ortho.callbacks.mlflow import MlFlowCallBack\n",
    "from ortho.ortho.callbacks.logger import LoggerCallBack\n",
    "import os\n",
    "\n",
    "\n",
    "logger = Logger().logger()\n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> project_dir: /home/jupyter-aamir09/mlops2_with_dagster\n"
     ]
    }
   ],
   "source": [
    "project = 'mlops2_with_dagster'\n",
    "project_dir = get_project_dir(project)\n",
    "printse(f'project_dir: {project_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_file: Path = project_dir/\"intermediate_data/encoder.joblib\"\n",
    "data: Path = project_dir/\"data/test.csv\"\n",
    "datatype: str = \"dataset\"\n",
    "model_file: Path = project_dir/\"models/rf.joblib\"\n",
    "infer_type: str = \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-aamir09/.conda/envs/test_with_poetry/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.1.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jupyter-aamir09/mlops2_with_dagster/models/rf.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(data)\n\u001b[1;32m      3\u001b[0m encoders \u001b[39m=\u001b[39m load(encoder_file)\n\u001b[0;32m----> 4\u001b[0m clfinfo \u001b[39m=\u001b[39m load(model_file)\n",
      "File \u001b[0;32m~/.conda/envs/test_with_poetry/lib/python3.10/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[39mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jupyter-aamir09/mlops2_with_dagster/models/rf.joblib'"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "df = pd.read_csv(data)\n",
    "encoders = load(encoder_file)\n",
    "clfinfo = load(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Infer:\n",
    "    \n",
    "    def __init__(self, callbacks,  experiment_name, run_name, load_from_artifact=False):\n",
    "        self.load_from_artifact = load_from_artifact\n",
    "        self.callbacks = callbacks\n",
    "        self.experiment_name = experiment_name\n",
    "        self.run_name = run_name\n",
    "        os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = self.experiment_name\n",
    "        os.environ[\"MLFLOW_RUN_NAME\"] = self.run_name\n",
    "        \n",
    "        self.index_col = 'passengerid'\n",
    "        self.target_col = \"survived\"\n",
    "        self.cat_cols = [\"sex\", \"cabin\", \"embarked\"]\n",
    "        self.config = {\n",
    "            'index_column': self.index_col,\n",
    "            'target_column': self.target_col,\n",
    "            'categorical_columns': self.cat_cols\n",
    "        }\n",
    "        self.config_model = {\n",
    "            'index_column': self.index_col,\n",
    "            'target_column': self.target_col,\n",
    "            'random_state': 42,\n",
    "            'max_depth': None,\n",
    "            'validation_size_fraction': 0.33,\n",
    "            't': 0.5\n",
    "            }\n",
    "            \n",
    "        self.config_infer2 = {\n",
    "            'index_column': self.index_col,\n",
    "            'target_column': self.target_col,\n",
    "            't': 0.5\n",
    "            }\n",
    "\n",
    "    \n",
    "    @task(build_on_previous_run=True, end_mlflow_run=False)       \n",
    "    def inference(self, df_test=None, encoders=None, clfinfo=None):\n",
    "        infer2_adapter = base.SimplePythonGraphAdapter(base.DictResult())\n",
    "        infer2_dr = driver.Driver(self.config_infer2, \n",
    "                                    features_pipeline, model_pipeline, encoder_pipeline,\n",
    "                                    adapter = infer2_adapter)\n",
    "        dinfer2 = dict(\n",
    "            df = df_test,\n",
    "            clf = clfinfo['fit_clf'],\n",
    "            **encoders['encoders']\n",
    "        )\n",
    "        output_nodes = ['chain_predictions']\n",
    "        \n",
    "        output = infer2_dr.execute(output_nodes, inputs  = dinfer2)\n",
    "        \n",
    "        data = {\"inference_results\": output }\n",
    "        payload = {\"artifact_path\": \"/home/jupyter-aamir09/mlops2_with_dagster/artifacts/mlflow_artfacts\",\n",
    "                   \"params\": self.config_infer2}\n",
    "        \n",
    "        return data, payload\n",
    "    \n",
    "    def run(self, *args, **kwargs):\n",
    "        \n",
    "        return self.inference(*args, **kwargs)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:13:48,162 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,168 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=Mlflow_with_Dagster HTTP/1.1\" 200 241\n",
      "2023-08-30 13:13:48,170 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,177 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=1f0a6e058efb4c5d9e9fbecc36928d78&run_id=1f0a6e058efb4c5d9e9fbecc36928d78 HTTP/1.1\" 200 1260\n",
      "2023-08-30 13:13:48,179 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,184 - DEBUG - http://127.0.0.1:5002 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 423\n",
      "2023-08-30 13:13:48,186 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,191 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=1f0a6e058efb4c5d9e9fbecc36928d78&run_id=1f0a6e058efb4c5d9e9fbecc36928d78 HTTP/1.1\" 200 1260\n",
      "2023-08-30 13:13:48,192 - INFO - Successfuly initiated run with name BadamBhum and id 1f0a6e058efb4c5d9e9fbecc36928d78\n",
      "2023-08-30 13:13:48,192 - INFO - Active run_id recieved as 1f0a6e058efb4c5d9e9fbecc36928d78\n",
      "2023-08-30 13:13:48,192 - INFO - Active run_id recieved as 1f0a6e058efb4c5d9e9fbecc36928d78\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:46: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  print(client.download_artifacts(mlflow_run_id, fname))\n",
      "2023-08-30 13:13:48,194 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,196 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Fdf_train.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:13:48,198 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,200 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 13:13:48,200 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle'): Retry(total=4, connect=5, read=5, redirect=5, status=4)\n",
      "2023-08-30 13:13:48,201 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle\n",
      "2023-08-30 13:13:48,201 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:48,203 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 13:13:48,203 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle'): Retry(total=3, connect=5, read=5, redirect=5, status=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self', 'df_train', 'encoders']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:13:52,208 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle\n",
      "2023-08-30 13:13:52,210 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:13:52,215 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 13:13:52,216 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle'): Retry(total=2, connect=5, read=5, redirect=5, status=2)\n",
      "2023-08-30 13:14:00,226 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle\n",
      "2023-08-30 13:14:00,228 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:00,233 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 13:14:00,234 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle'): Retry(total=1, connect=5, read=5, redirect=5, status=1)\n",
      "2023-08-30 13:14:16,251 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle\n",
      "2023-08-30 13:14:16,253 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:16,258 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 13:14:16,259 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle'): Retry(total=0, connect=5, read=5, redirect=5, status=0)\n",
      "2023-08-30 13:14:48,293 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle\n",
      "2023-08-30 13:14:48,295 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,299 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 13:14:48,300 - INFO - The following error occured while loading files from artefact store, The following failures occurred while downloading one or more artifacts from http://127.0.0.1:5002/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts: {'df_train.pickle': 'MlflowException(\"API request to http://127.0.0.1:5002/api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle failed with exception HTTPConnectionPool(host=\\'127.0.0.1\\', port=5002): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/df_train.pickle (Caused by ResponseError(\\'too many 500 error responses\\'))\")'}\n",
      "2023-08-30 13:14:48,306 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,308 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Fencoders.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:14:48,310 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,312 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/encoders.pickle HTTP/1.1\" 200 None\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:47: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  inputs.append(pickle.load(open(client.download_artifacts(mlflow_run_id, fname), \"rb\")))\n",
      "2023-08-30 13:14:48,315 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,317 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Fencoders.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:14:48,319 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,321 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/encoders.pickle HTTP/1.1\" 200 None\n",
      "2023-08-30 13:14:48,322 - INFO - Succesfully loaded file with name encoders.pickle\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:49: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  response[fname.replace(\".pickle\", \"\")] = pickle.load(open(client.download_artifacts(mlflow_run_id, fname), \"rb\"))\n",
      "2023-08-30 13:14:48,326 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,328 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1f0a6e058efb4c5d9e9fbecc36928d78%2Fartifacts%2Fencoders.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:14:48,330 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,332 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/encoders.pickle HTTP/1.1\" 200 None\n",
      "2023-08-30 13:14:48,338 - DEBUG - Computing df.\n",
      "2023-08-30 13:14:48,339 - DEBUG - Computing index_column.\n",
      "2023-08-30 13:14:48,339 - DEBUG - Computing input_data.\n",
      "2023-08-30 13:14:48,349 - DEBUG - Computing target_column.\n",
      "2023-08-30 13:14:48,349 - DEBUG - Computing features.\n",
      "2023-08-30 13:14:48,357 - DEBUG - Computing pclass.\n",
      "2023-08-30 13:14:48,358 - DEBUG - Computing age.\n",
      "2023-08-30 13:14:48,358 - DEBUG - Computing fare.\n",
      "2023-08-30 13:14:48,359 - DEBUG - Computing cabin.\n",
      "2023-08-30 13:14:48,359 - DEBUG - Computing cabin_t.\n",
      "2023-08-30 13:14:48,374 - DEBUG - Computing cabinencoder.\n",
      "2023-08-30 13:14:48,375 - DEBUG - Computing cabin_category.\n",
      "2023-08-30 13:14:48,432 - DEBUG - Computing sex.\n",
      "2023-08-30 13:14:48,433 - DEBUG - Computing sexencoder.\n",
      "2023-08-30 13:14:48,433 - DEBUG - Computing sex_category.\n",
      "2023-08-30 13:14:48,444 - DEBUG - Computing embarked.\n",
      "2023-08-30 13:14:48,444 - DEBUG - Computing embarkedencoder.\n",
      "2023-08-30 13:14:48,444 - DEBUG - Computing embarked_category.\n",
      "2023-08-30 13:14:48,453 - DEBUG - Computing sibsp.\n",
      "2023-08-30 13:14:48,454 - DEBUG - Computing parch.\n",
      "2023-08-30 13:14:48,454 - DEBUG - Computing family.\n",
      "2023-08-30 13:14:48,455 - DEBUG - Computing engineered_features.\n",
      "2023-08-30 13:14:48,461 - DEBUG - Computing final_imputed_features.\n",
      "2023-08-30 13:14:48,467 - DEBUG - Index types encountered:\n",
      "{'Index:::int64': ['final_imputed_features']}.\n",
      "2023-08-30 13:14:48,472 - INFO - Successfuly stored transformed_data to /home/jupyter-aamir09/mlops2_with_dagster/artifacts/mlflow_artfacts/transformed_data.pickle\n",
      "2023-08-30 13:14:48,475 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,485 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/target.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:14:48,487 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 13:14:48,511 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/transformed_data.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 13:14:48,513 - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmptyislrj1/encoders.pickle\n",
      "{'encoders': {'encoders': {'cabinencoder': LabelEncoder(), 'sexencoder': LabelEncoder(), 'embarkedencoder': LabelEncoder()}}}\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:14:48,515 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/encoders.pickle HTTP/1.1\" 200 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin_category</th>\n",
       "      <th>sex_category</th>\n",
       "      <th>embarked_category</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passengerid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.35</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "      <td>71.29</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19.00</td>\n",
       "      <td>13.04</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>25.00</td>\n",
       "      <td>7.76</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>2</td>\n",
       "      <td>62.00</td>\n",
       "      <td>14.86</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>2</td>\n",
       "      <td>66.00</td>\n",
       "      <td>11.15</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>3</td>\n",
       "      <td>37.00</td>\n",
       "      <td>9.95</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>3</td>\n",
       "      <td>51.00</td>\n",
       "      <td>30.92</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>3</td>\n",
       "      <td>55.00</td>\n",
       "      <td>13.96</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pclass    age   fare  cabin_category  sex_category  \\\n",
       "passengerid                                                       \n",
       "0                 1   0.00  27.14               2             1   \n",
       "1                 3   0.00  13.35               8             1   \n",
       "2                 3   0.33  71.29               8             1   \n",
       "3                 3  19.00  13.04               8             1   \n",
       "4                 3  25.00   7.76               8             1   \n",
       "...             ...    ...    ...             ...           ...   \n",
       "99995             2  62.00  14.86               3             0   \n",
       "99996             2  66.00  11.15               8             1   \n",
       "99997             3  37.00   9.95               8             1   \n",
       "99998             3  51.00  30.92               8             1   \n",
       "99999             3  55.00  13.96               8             1   \n",
       "\n",
       "             embarked_category  family  \n",
       "passengerid                             \n",
       "0                            2       2  \n",
       "1                            2       0  \n",
       "2                            2       3  \n",
       "3                            2       0  \n",
       "4                            2       0  \n",
       "...                        ...     ...  \n",
       "99995                        0       0  \n",
       "99996                        2       0  \n",
       "99997                        2       0  \n",
       "99998                        2       1  \n",
       "99999                        2       0  \n",
       "\n",
       "[100000 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 13:14:48,630 - DEBUG - Succeed in sending telemetry consisting of [b'{\"api_key\": \"phc_mZg8bkn3yvMxqvZKRlMlxjekFU5DFDdcdAsijJ2EH5e\", \"event\": \"os_hamilton_run_start\", \"properties\": {\"os_type\": \"posix\", \"os_version\": \"Linux-5.4.0-124-generic-x86_64-with-glibc2.31\", \"python_version\": \"3.10.12/CPython\", \"distinct_id\": \"e4e272c1-5845-4b12-8bd8-09d84d585dbc\", \"hamilton_version\": [1, 27, 2], \"telemetry_version\": \"0.0.1\", \"number_of_nodes\": 42, \"number_of_modules\": 2, \"number_of_config_items\": 3, \"decorators_used\": {\"parameterize_sources\": 4, \"extract_columns\": 2, \"extract_fields\": 1}, \"graph_adapter_used\": \"hamilton.base.SimplePythonDataFrameGraphAdapter\", \"result_builder_used\": \"hamilton.base.PandasDataFrameResult\", \"driver_run_id\": \"88beb813-e398-4538-b488-766ef32a2c10\", \"error\": null, \"graph_executor_class\": \"DefaultGraphExecutor\"}}'].\n",
      "2023-08-30 13:14:48,710 - DEBUG - Succeed in sending telemetry consisting of [b'{\"api_key\": \"phc_mZg8bkn3yvMxqvZKRlMlxjekFU5DFDdcdAsijJ2EH5e\", \"event\": \"os_hamilton_run_end\", \"properties\": {\"os_type\": \"posix\", \"os_version\": \"Linux-5.4.0-124-generic-x86_64-with-glibc2.31\", \"python_version\": \"3.10.12/CPython\", \"distinct_id\": \"e4e272c1-5845-4b12-8bd8-09d84d585dbc\", \"hamilton_version\": [1, 27, 2], \"telemetry_version\": \"0.0.1\", \"is_success\": true, \"runtime_seconds\": 0.1288890838623047, \"number_of_outputs\": 1, \"number_of_overrides\": 0, \"number_of_inputs\": 0, \"driver_run_id\": \"88beb813-e398-4538-b488-766ef32a2c10\", \"error\": null}}'].\n"
     ]
    }
   ],
   "source": [
    "import dagstermill\n",
    "inferencer = Infer(experiment_name=\"Mlflow_with_Dagster\",\n",
    "                          run_name=\"BadamBhum\",\n",
    "                          callbacks = [LoggerCallBack(\"/home/jupyter-aamir09/mlops2_with_dagster/notebooks\", kernel_names=[\"inference\"]),\n",
    "                                       MlFlowCallBack(kernel_names=[\"inference\"])],\n",
    "                          load_from_artifact=False)\n",
    "\n",
    "# mf.end_run()\n",
    "dagstermill.yield_result(inferencer.run(df_test=df, encoders=encoders, clfinfo=clfinfo)[0][\"inference_results\"], output_name=\"inference_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_with_poetry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
