{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 19:07:25.746144: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-30 19:07:25.780683: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-30 19:07:25.781272: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-30 19:07:26,271 - DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2023-08-30 19:07:26.324683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-30 19:07:26,451 - DEBUG - Creating converter from 7 to 5\n",
      "2023-08-30 19:07:26,452 - DEBUG - Creating converter from 5 to 7\n",
      "2023-08-30 19:07:26,453 - DEBUG - Creating converter from 7 to 5\n",
      "2023-08-30 19:07:26,453 - DEBUG - Creating converter from 5 to 7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jupyter-aamir09/mlops2_with_dagster/\")\n",
    "\n",
    "\n",
    "from mlops2_with_dagster import encoder_pipeline\n",
    "from pathlib import Path\n",
    "from joblib import dump, load\n",
    "from hamilton import driver, base\n",
    "from mlops2_with_dagster.utils import get_project_dir, printse\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    LabelEncoder\n",
    ")\n",
    "from ortho.utils.logger import Logger\n",
    "from ortho.ortho.decorators.task import task\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd \n",
    "import mlflow as mf\n",
    "from ortho.ortho.callbacks.mlflow import MlFlowCallBack\n",
    "from ortho.ortho.callbacks.logger import LoggerCallBack\n",
    "import os\n",
    "\n",
    "\n",
    "logger = Logger().logger()\n",
    "\n",
    "\n",
    "# class MyProcessor(PreProcessor):\n",
    "    \n",
    "#     def __init__(self, callbacks,  experiment_name, run_name, load_from_artifact=False):\n",
    "#         self.load_from_artifact = load_from_artifact\n",
    "#         self.callbacks = callbacks\n",
    "#         self.experiment_name = experiment_name\n",
    "#         self.run_name = run_name\n",
    "#         os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = self.experiment_name\n",
    "#         os.environ[\"MLFLOW_RUN_NAME\"] = self.run_name\n",
    "    \n",
    "#     @task(end_mlflow_run=True)\n",
    "#     def train_processor(self, training_data):\n",
    "        \n",
    "    #     data, _ , params = preprocess(training_data.copy(), training_data.copy())\n",
    "        \n",
    "    #     payload = {\"artifact_path\":\"/home/jupyter-aamir09/dagster_pipeline_2/artefacts\"}\n",
    "        \n",
    "    #     return {\"train_x\":data.drop(\"target\", axis =1),\n",
    "    #             \"train_y\": data[\"target\"], \n",
    "    #             \"processor_params\": params}, payload\n",
    "    \n",
    "    # def inference_preprocessor(self, infer_data, params):\n",
    "    \n",
    "    #     data = inference_preprocess(infer_data.copy(), params)\n",
    "        \n",
    "\n",
    "        # payload = {\"artifacts_path\":\"/home/jupyter-aamir09/dagster_pipeline_2/artefacts\"}\n",
    "        \n",
    "        # return {\"inference_data\":data}, payload\n",
    "        \n",
    "        \n",
    "        \n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "#     data_path = \"/home/jupyter-aamir09/dagster_pipeline_2/data/raw/train.csv\"\n",
    "    \n",
    "#     data = pd.read_csv(data_path)\n",
    "    \n",
    "#     processor = MyProcessor(filenames=[], \n",
    "#                             callbacks=[MlFlowCallBack(kernel_names=[\"train_processor\"])])\n",
    "    \n",
    "#     processor.train_processor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> project_dir: /home/jupyter-aamir09/mlops2_with_dagster\n"
     ]
    }
   ],
   "source": [
    "project = 'mlops2_with_dagster'\n",
    "project_dir = get_project_dir(project)\n",
    "printse(f'project_dir: {project_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    \n",
    "    def __init__(self, callbacks,  experiment_name, run_name, load_from_artifact=False):\n",
    "        self.load_from_artifact = load_from_artifact\n",
    "        self.callbacks = callbacks\n",
    "        self.experiment_name = experiment_name\n",
    "        self.run_name = run_name\n",
    "        os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = self.experiment_name\n",
    "        os.environ[\"MLFLOW_RUN_NAME\"] = self.run_name\n",
    "        \n",
    "        self.index_col = 'passengerid'\n",
    "        self.target_col = \"survived\"\n",
    "        self.cat_cols = [\"sex\", \"cabin\", \"embarked\"]\n",
    "        self.config = {\n",
    "            'index_column': self.index_col,\n",
    "            'target_column': self.target_col,\n",
    "            'categorical_columns': self.cat_cols\n",
    "        }\n",
    "    \n",
    "    @task()       \n",
    "    def create_encoders(self, df_train, df_test):\n",
    "        adapter = base.SimplePythonGraphAdapter(base.DictResult())\n",
    "        encode_dr = driver.Driver(self.config, encoder_pipeline, adapter=adapter)\n",
    "        output_nodes = ['encoders']\n",
    "        \n",
    "        out = encode_dr.execute(output_nodes ,\n",
    "        inputs = dict(\n",
    "            df_train = df_train,\n",
    "            df_test = df_test\n",
    "        )         \n",
    "        )\n",
    "        \n",
    "        data = {\"encoders\": out }\n",
    "        payload = {\"params\":self.config,\n",
    "                   \"artifact_path\": \"/home/jupyter-aamir09/mlops2_with_dagster/artifacts/mlflow_artfacts\"}\n",
    "        \n",
    "        return data, payload\n",
    "    \n",
    "    def run(self, *args, **kwargs):\n",
    "        \n",
    "        return self.create_encoders(*args, **kwargs)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data : Path = project_dir/\"data/train.csv\"\n",
    "test_data : Path = project_dir/\"data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "df_train = pd.read_csv(train_data)\n",
    "df_test = pd.read_csv(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 19:07:27,113 - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5002\n",
      "2023-08-30 19:07:27,122 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=Mlflow_with_Dagster HTTP/1.1\" 200 241\n",
      "2023-08-30 19:07:27,146 - DEBUG - Popen(['git', 'version'], cwd=/home/jupyter-aamir09/mlops2_with_dagster/notebooks, universal_newlines=False, shell=None, istream=None)\n",
      "2023-08-30 19:07:27,149 - DEBUG - Popen(['git', 'version'], cwd=/home/jupyter-aamir09/mlops2_with_dagster/notebooks, universal_newlines=False, shell=None, istream=None)\n",
      "2023-08-30 19:07:27,154 - DEBUG - Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'No such file or directory')\n",
      "2023-08-30 19:07:27,157 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:07:27,169 - DEBUG - http://127.0.0.1:5002 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 918\n",
      "2023-08-30 19:07:27,170 - INFO - Successfuly initiated run with name BadamBhum and id 1979dcd81bfb4588a25f196d619475b5\n",
      "2023-08-30 19:07:27,171 - INFO - Active run_id recieved as 1979dcd81bfb4588a25f196d619475b5\n",
      "2023-08-30 19:07:27,171 - INFO - Active run_id recieved as 1979dcd81bfb4588a25f196d619475b5\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:46: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  print(client.download_artifacts(mlflow_run_id, fname))\n",
      "2023-08-30 19:07:27,175 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:07:27,179 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=1979dcd81bfb4588a25f196d619475b5&run_id=1979dcd81bfb4588a25f196d619475b5 HTTP/1.1\" 200 918\n",
      "2023-08-30 19:07:27,182 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:07:27,183 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1979dcd81bfb4588a25f196d619475b5%2Fartifacts%2Fdf_train.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 19:07:27,187 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:07:27,190 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 19:07:27,190 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle'): Retry(total=4, connect=5, read=5, redirect=5, status=4)\n",
      "2023-08-30 19:07:27,191 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle\n",
      "2023-08-30 19:07:27,192 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:07:27,194 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 19:07:27,194 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle'): Retry(total=3, connect=5, read=5, redirect=5, status=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self', 'df_train', 'df_test']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 19:07:31,199 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle\n",
      "2023-08-30 19:07:31,201 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:07:31,206 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 19:07:31,207 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle'): Retry(total=2, connect=5, read=5, redirect=5, status=2)\n",
      "2023-08-30 19:07:39,216 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle\n",
      "2023-08-30 19:07:39,218 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:07:39,222 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 19:07:39,223 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle'): Retry(total=1, connect=5, read=5, redirect=5, status=1)\n",
      "2023-08-30 19:07:55,240 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle\n",
      "2023-08-30 19:07:55,242 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:07:55,247 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 19:07:55,247 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle'): Retry(total=0, connect=5, read=5, redirect=5, status=0)\n",
      "2023-08-30 19:08:27,262 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle\n",
      "2023-08-30 19:08:27,264 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:08:27,268 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle HTTP/1.1\" 500 258\n",
      "2023-08-30 19:08:27,269 - INFO - The following error occured while loading files from artefact store, The following failures occurred while downloading one or more artifacts from http://127.0.0.1:5002/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts: {'df_train.pickle': 'MlflowException(\"API request to http://127.0.0.1:5002/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle failed with exception HTTPConnectionPool(host=\\'127.0.0.1\\', port=5002): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_train.pickle (Caused by ResponseError(\\'too many 500 error responses\\'))\")'}\n",
      "2023-08-30 19:08:27,274 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:08:27,277 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts?path=1%2F1979dcd81bfb4588a25f196d619475b5%2Fartifacts%2Fdf_test.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 19:08:27,280 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:08:27,283 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle HTTP/1.1\" 500 257\n",
      "2023-08-30 19:08:27,283 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle'): Retry(total=4, connect=5, read=5, redirect=5, status=4)\n",
      "2023-08-30 19:08:27,284 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle\n",
      "2023-08-30 19:08:27,284 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:08:27,286 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle HTTP/1.1\" 500 257\n",
      "2023-08-30 19:08:27,287 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle'): Retry(total=3, connect=5, read=5, redirect=5, status=3)\n",
      "2023-08-30 19:08:31,291 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle\n",
      "2023-08-30 19:08:31,293 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:08:31,298 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle HTTP/1.1\" 500 257\n",
      "2023-08-30 19:08:31,299 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle'): Retry(total=2, connect=5, read=5, redirect=5, status=2)\n",
      "2023-08-30 19:08:39,309 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle\n",
      "2023-08-30 19:08:39,310 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:08:39,315 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle HTTP/1.1\" 500 257\n",
      "2023-08-30 19:08:39,316 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle'): Retry(total=1, connect=5, read=5, redirect=5, status=1)\n",
      "2023-08-30 19:08:55,333 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle\n",
      "2023-08-30 19:08:55,335 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:08:55,340 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle HTTP/1.1\" 500 257\n",
      "2023-08-30 19:08:55,341 - DEBUG - Incremented Retry for (url='/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle'): Retry(total=0, connect=5, read=5, redirect=5, status=0)\n",
      "2023-08-30 19:09:27,375 - DEBUG - Retry: /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle\n",
      "2023-08-30 19:09:27,377 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:09:27,382 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle HTTP/1.1\" 500 257\n",
      "2023-08-30 19:09:27,383 - INFO - The following error occured while loading files from artefact store, The following failures occurred while downloading one or more artifacts from http://127.0.0.1:5002/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts: {'df_test.pickle': 'MlflowException(\"API request to http://127.0.0.1:5002/api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle failed with exception HTTPConnectionPool(host=\\'127.0.0.1\\', port=5002): Max retries exceeded with url: /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/df_test.pickle (Caused by ResponseError(\\'too many 500 error responses\\'))\")'}\n",
      "2023-08-30 19:09:27,386 - WARNING - Note: Hamilton collects completely anonymous data about usage. This will help us improve Hamilton over time. See https://github.com/dagworks-inc/hamilton#usage-analytics--data-privacy for details.\n",
      "2023-08-30 19:09:27,388 - DEBUG - Computing df_train.\n",
      "2023-08-30 19:09:27,389 - DEBUG - Computing index_column.\n",
      "2023-08-30 19:09:27,390 - DEBUG - Computing input_data_train.\n",
      "2023-08-30 19:09:27,396 - DEBUG - Computing df_test.\n",
      "2023-08-30 19:09:27,397 - DEBUG - Computing input_data_test.\n",
      "2023-08-30 19:09:27,402 - DEBUG - Computing categorical_columns.\n",
      "2023-08-30 19:09:27,403 - DEBUG - Computing combined_categoricals.\n",
      ">>>> Index(['sex', 'cabin', 'embarked'], dtype='object')\n",
      "2023-08-30 19:09:27,413 - DEBUG - Computing combined_cabin.\n",
      "2023-08-30 19:09:27,415 - DEBUG - Computing combined_cabin_t.\n",
      ">>> <class 'pandas.core.series.Series'> 200000 ['C12239' nan nan nan nan nan nan nan 'A7253' 'D2969' nan 'A9055' 'C8674'\n",
      " nan 'D6945' nan nan nan nan 'B7010' nan nan nan nan nan 'B11790' nan\n",
      " 'C20297' nan nan nan nan nan 'B16390' nan nan 'C19277' 'B7665' nan nan\n",
      " 'D6224' nan 'B21244' nan nan nan nan 'D1695' nan nan 'C12615' nan\n",
      " 'D19734' 'C11880' nan nan 'A19055' 'D6286' nan nan nan nan nan 'A6932'\n",
      " nan nan 'C15652' 'B4480' 'C5522' nan 'A19030' nan nan 'D19747' nan nan\n",
      " nan nan nan nan nan nan 'B19226' nan nan nan nan nan nan 'A18210' nan\n",
      " 'B5371' nan nan 'C11610' nan nan 'D7415' nan 'C16097']\n",
      "2023-08-30 19:09:27,443 - DEBUG - Computing cabin_encoder.\n",
      "2023-08-30 19:09:27,447 - DEBUG - Computing combined_sex.\n",
      "2023-08-30 19:09:27,448 - DEBUG - Computing sex_encoder.\n",
      "2023-08-30 19:09:27,453 - DEBUG - Computing combined_embarked.\n",
      "2023-08-30 19:09:27,454 - DEBUG - Computing embarked_encoder.\n",
      "2023-08-30 19:09:27,456 - DEBUG - Computing encoders.\n",
      "2023-08-30 19:09:27,459 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:09:27,481 - DEBUG - http://127.0.0.1:5002 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2023-08-30 19:09:27,484 - INFO - Successfuly stored encoders to /home/jupyter-aamir09/mlops2_with_dagster/artifacts/mlflow_artfacts/encoders.pickle\n",
      "2023-08-30 19:09:27,492 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:09:27,503 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/target.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 19:09:27,505 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:09:27,528 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/transformed_data.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 19:09:27,530 - DEBUG - Resetting dropped connection: 127.0.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 19:09:27,656 - DEBUG - Succeed in sending telemetry consisting of [b'{\"api_key\": \"phc_mZg8bkn3yvMxqvZKRlMlxjekFU5DFDdcdAsijJ2EH5e\", \"event\": \"os_hamilton_run_start\", \"properties\": {\"os_type\": \"posix\", \"os_version\": \"Linux-5.4.0-124-generic-x86_64-with-glibc2.31\", \"python_version\": \"3.10.12/CPython\", \"distinct_id\": \"e4e272c1-5845-4b12-8bd8-09d84d585dbc\", \"hamilton_version\": [1, 27, 2], \"telemetry_version\": \"0.0.1\", \"number_of_nodes\": 32, \"number_of_modules\": 1, \"number_of_config_items\": 3, \"decorators_used\": {\"parameterize_sources\": 4, \"extract_columns\": 2, \"extract_fields\": 1}, \"graph_adapter_used\": \"hamilton.base.SimplePythonGraphAdapter\", \"result_builder_used\": \"hamilton.base.DictResult\", \"driver_run_id\": \"f7c6265c-4894-4121-b201-85574ec39aa8\", \"error\": null, \"graph_executor_class\": \"DefaultGraphExecutor\"}}'].\n",
      "2023-08-30 19:09:27,696 - DEBUG - Succeed in sending telemetry consisting of [b'{\"api_key\": \"phc_mZg8bkn3yvMxqvZKRlMlxjekFU5DFDdcdAsijJ2EH5e\", \"event\": \"os_hamilton_run_end\", \"properties\": {\"os_type\": \"posix\", \"os_version\": \"Linux-5.4.0-124-generic-x86_64-with-glibc2.31\", \"python_version\": \"3.10.12/CPython\", \"distinct_id\": \"e4e272c1-5845-4b12-8bd8-09d84d585dbc\", \"hamilton_version\": [1, 27, 2], \"telemetry_version\": \"0.0.1\", \"is_success\": true, \"runtime_seconds\": 0.06882143020629883, \"number_of_outputs\": 1, \"number_of_overrides\": 0, \"number_of_inputs\": 0, \"driver_run_id\": \"f7c6265c-4894-4121-b201-85574ec39aa8\", \"error\": null}}'].\n",
      "2023-08-30 19:09:28,247 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/training_outputs.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 19:09:28,253 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:09:28,256 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1979dcd81bfb4588a25f196d619475b5/artifacts/encoders.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 19:09:28,261 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 19:09:28,279 - DEBUG - http://127.0.0.1:5002 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'encoders': {'cabinencoder': LabelEncoder(),\n",
       "  'sexencoder': LabelEncoder(),\n",
       "  'embarkedencoder': LabelEncoder()}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagstermill\n",
    "encoders_object = Encoder(experiment_name=\"Mlflow_with_Dagster\",\n",
    "                          run_name=\"BadamBhum\",\n",
    "                          callbacks = [LoggerCallBack(\"/home/jupyter-aamir09/mlops2_with_dagster/notebooks\", kernel_names=[\"create_encoders\"]),\n",
    "                                       MlFlowCallBack(kernel_names=[\"create_encoders\"])])\n",
    "\n",
    "mf.end_run()\n",
    "dagstermill.yield_result(encoders_object.run(df_train=df_train,\n",
    "                                            df_test=df_test)[0][\"encoders\"], output_name=\"encoders\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_with_poetry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
