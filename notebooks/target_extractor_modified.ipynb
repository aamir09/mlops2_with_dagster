{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 12:37:51.234607: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-30 12:37:51.266881: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-30 12:37:51.267673: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-30 12:37:51,741 - DEBUG - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2023-08-30 12:37:51.793885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-30 12:37:51,919 - DEBUG - Creating converter from 7 to 5\n",
      "2023-08-30 12:37:51,920 - DEBUG - Creating converter from 5 to 7\n",
      "2023-08-30 12:37:51,921 - DEBUG - Creating converter from 7 to 5\n",
      "2023-08-30 12:37:51,921 - DEBUG - Creating converter from 5 to 7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jupyter-aamir09/mlops2_with_dagster/\")\n",
    "\n",
    "\n",
    "from mlops2_with_dagster import encoder_pipeline\n",
    "from pathlib import Path\n",
    "from joblib import dump, load\n",
    "from hamilton import driver, base\n",
    "from mlops2_with_dagster.utils import get_project_dir, printse\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    LabelEncoder\n",
    ")\n",
    "from ortho.utils.logger import Logger\n",
    "from ortho.ortho.decorators.task import task\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd \n",
    "import mlflow as mf\n",
    "from ortho.ortho.callbacks.mlflow import MlFlowCallBack\n",
    "from ortho.ortho.callbacks.logger import LoggerCallBack\n",
    "import os\n",
    "\n",
    "\n",
    "logger = Logger().logger()\n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>> project_dir: /home/jupyter-aamir09/mlops2_with_dagster\n"
     ]
    }
   ],
   "source": [
    "project = 'mlops2_with_dagster'\n",
    "project_dir = get_project_dir(project)\n",
    "printse(f'project_dir: {project_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetExtractor:\n",
    "    \n",
    "    def __init__(self, callbacks,  experiment_name, run_name, load_from_artifact=False):\n",
    "        self.load_from_artifact = load_from_artifact\n",
    "        self.callbacks = callbacks\n",
    "        self.experiment_name = experiment_name\n",
    "        self.run_name = run_name\n",
    "        os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = self.experiment_name\n",
    "        os.environ[\"MLFLOW_RUN_NAME\"] = self.run_name\n",
    "        \n",
    "        self.index_col = 'passengerid'\n",
    "        self.target_col = \"survived\"\n",
    "        self.cat_cols = [\"sex\", \"cabin\", \"embarked\"]\n",
    "        self.config = {\n",
    "            'index_column': self.index_col,\n",
    "            'target_column': self.target_col,\n",
    "            'categorical_columns': self.cat_cols\n",
    "        }\n",
    "    \n",
    "    @task(build_on_previous_run=True, end_mlflow_run=False)       \n",
    "    def get_target(self, df_train):\n",
    "        encode_dr = driver.Driver(self.config, encoder_pipeline)\n",
    "        output_nodes = ['target']\n",
    "        \n",
    "        out = encode_dr.execute(output_nodes ,\n",
    "        inputs = dict(\n",
    "            df_train = df_train\n",
    "        )         \n",
    "        )\n",
    "        \n",
    "        data = {\"target\": out }\n",
    "        payload = {\"artifact_path\": \"/home/jupyter-aamir09/mlops2_with_dagster/artifacts/mlflow_artfacts\"}\n",
    "        \n",
    "        return data, payload\n",
    "    \n",
    "    def run(self, *args, **kwargs):\n",
    "        \n",
    "        return self.get_target(*args, **kwargs)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data : Path = project_dir/\"data/train.csv\"\n",
    "test_data : Path = project_dir/\"data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "df_train = pd.read_csv(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 12:37:52,456 - DEBUG - Starting new HTTP connection (1): 127.0.0.1:5002\n",
      "2023-08-30 12:37:52,462 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/experiments/get-by-name?experiment_name=Mlflow_with_Dagster HTTP/1.1\" 200 241\n",
      "2023-08-30 12:37:52,464 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 12:37:52,469 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=1f0a6e058efb4c5d9e9fbecc36928d78&run_id=1f0a6e058efb4c5d9e9fbecc36928d78 HTTP/1.1\" 200 1261\n",
      "2023-08-30 12:37:52,471 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 12:37:52,482 - DEBUG - http://127.0.0.1:5002 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 423\n",
      "2023-08-30 12:37:52,484 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 12:37:52,488 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=1f0a6e058efb4c5d9e9fbecc36928d78&run_id=1f0a6e058efb4c5d9e9fbecc36928d78 HTTP/1.1\" 200 1260\n",
      "2023-08-30 12:37:52,489 - INFO - Successfuly initiated run with name BadamBhum and id 1f0a6e058efb4c5d9e9fbecc36928d78\n",
      "2023-08-30 12:37:52,489 - INFO - Active run_id recieved as 1f0a6e058efb4c5d9e9fbecc36928d78\n",
      "\n",
      "2023-08-30 12:37:52,489 - INFO - Active run_id recieved as 1f0a6e058efb4c5d9e9fbecc36928d78\n",
      "\n",
      "/home/jupyter-aamir09/dagster_pipeline_2/dagster_pipeline_2/ortho/ortho/decorators/task.py:44: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  print(client.download_artifacts(mlflow_run_id, fname))\n",
      "2023-08-30 12:37:52,491 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 12:37:52,493 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=1f0a6e058efb4c5d9e9fbecc36928d78%0A&run_id=1f0a6e058efb4c5d9e9fbecc36928d78%0A HTTP/1.1\" 404 112\n",
      "2023-08-30 12:37:52,494 - INFO - The following error occured while loading files from artefact store, RESOURCE_DOES_NOT_EXIST: Run with id=1f0a6e058efb4c5d9e9fbecc36928d78\n",
      " not found\n",
      "2023-08-30 12:37:52,496 - WARNING - Note: Hamilton collects completely anonymous data about usage. This will help us improve Hamilton over time. See https://github.com/dagworks-inc/hamilton#usage-analytics--data-privacy for details.\n",
      "2023-08-30 12:37:52,498 - DEBUG - Computing df_train.\n",
      "2023-08-30 12:37:52,498 - DEBUG - Computing index_column.\n",
      "2023-08-30 12:37:52,499 - DEBUG - Computing input_data_train.\n",
      "2023-08-30 12:37:52,502 - DEBUG - Computing target_column.\n",
      "2023-08-30 12:37:52,503 - DEBUG - Computing target.\n",
      "2023-08-30 12:37:52,503 - DEBUG - Index types encountered:\n",
      "{'Index:::int64': ['target']}.\n",
      "2023-08-30 12:37:52,506 - INFO - Successfuly stored target to /home/jupyter-aamir09/mlops2_with_dagster/artifacts/mlflow_artfacts/target.pickle\n",
      "2023-08-30 12:37:52,509 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 12:37:52,514 - DEBUG - http://127.0.0.1:5002 \"GET /api/2.0/mlflow/runs/get?run_uuid=1f0a6e058efb4c5d9e9fbecc36928d78&run_id=1f0a6e058efb4c5d9e9fbecc36928d78 HTTP/1.1\" 200 1260\n",
      "2023-08-30 12:37:52,518 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 12:37:52,526 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/target.pickle HTTP/1.1\" 200 2\n",
      "2023-08-30 12:37:52,528 - DEBUG - Resetting dropped connection: 127.0.0.1\n",
      "2023-08-30 12:37:52,529 - DEBUG - http://127.0.0.1:5002 \"PUT /api/2.0/mlflow-artifacts/artifacts/1/1f0a6e058efb4c5d9e9fbecc36928d78/artifacts/encoders.pickle HTTP/1.1\" 200 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self', 'df_train']\n",
      "{}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passengerid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             target\n",
       "passengerid        \n",
       "0                 1\n",
       "1                 0\n",
       "2                 0\n",
       "3                 0\n",
       "4                 1\n",
       "...             ...\n",
       "99995             1\n",
       "99996             0\n",
       "99997             0\n",
       "99998             0\n",
       "99999             0\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 12:37:52,738 - DEBUG - Succeed in sending telemetry consisting of [b'{\"api_key\": \"phc_mZg8bkn3yvMxqvZKRlMlxjekFU5DFDdcdAsijJ2EH5e\", \"event\": \"os_hamilton_run_start\", \"properties\": {\"os_type\": \"posix\", \"os_version\": \"Linux-5.4.0-124-generic-x86_64-with-glibc2.31\", \"python_version\": \"3.10.12/CPython\", \"distinct_id\": \"e4e272c1-5845-4b12-8bd8-09d84d585dbc\", \"hamilton_version\": [1, 27, 2], \"telemetry_version\": \"0.0.1\", \"number_of_nodes\": 32, \"number_of_modules\": 1, \"number_of_config_items\": 3, \"decorators_used\": {\"parameterize_sources\": 4, \"extract_columns\": 2, \"extract_fields\": 1}, \"graph_adapter_used\": \"hamilton.base.SimplePythonDataFrameGraphAdapter\", \"result_builder_used\": \"hamilton.base.PandasDataFrameResult\", \"driver_run_id\": \"adc19a70-ca89-4225-9662-764512c0df14\", \"error\": null, \"graph_executor_class\": \"DefaultGraphExecutor\"}}'].\n",
      "2023-08-30 12:37:52,761 - DEBUG - Succeed in sending telemetry consisting of [b'{\"api_key\": \"phc_mZg8bkn3yvMxqvZKRlMlxjekFU5DFDdcdAsijJ2EH5e\", \"event\": \"os_hamilton_run_end\", \"properties\": {\"os_type\": \"posix\", \"os_version\": \"Linux-5.4.0-124-generic-x86_64-with-glibc2.31\", \"python_version\": \"3.10.12/CPython\", \"distinct_id\": \"e4e272c1-5845-4b12-8bd8-09d84d585dbc\", \"hamilton_version\": [1, 27, 2], \"telemetry_version\": \"0.0.1\", \"is_success\": true, \"runtime_seconds\": 0.0058286190032958984, \"number_of_outputs\": 1, \"number_of_overrides\": 0, \"number_of_inputs\": 0, \"driver_run_id\": \"adc19a70-ca89-4225-9662-764512c0df14\", \"error\": null}}'].\n"
     ]
    }
   ],
   "source": [
    "import dagstermill\n",
    "extractor = TargetExtractor(experiment_name=\"Mlflow_with_Dagster\",\n",
    "                          run_name=\"BadamBhum\",\n",
    "                          callbacks = [LoggerCallBack(\"/home/jupyter-aamir09/mlops2_with_dagster/notebooks\", kernel_names=[\"get_target\"]),\n",
    "                                       MlFlowCallBack(kernel_names=[\"get_target\"])])\n",
    "\n",
    "# mf.end_run()\n",
    "dagstermill.yield_result(extractor.run(df_train=df_train)[0][\"target\"], output_name=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_with_poetry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
